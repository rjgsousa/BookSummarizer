# Performance Assessment and Discussion

## Topic Modeling

Topic modeling was performed on the collection of books authored by Jane Austen using BERTopic with the transformer `all-MiniLM-L6-v2` embedding model. This  model is a lightweight version of the original BERT architecture that has been distilled and fine-tuned on a large corpus of text data. It efficiently generates semantically meaningful sentence embeddings that capture the contextual information necessary for downstream tasks like topic modeling.

The UMAP dimensionality reduction algorithm was applied to the sentence embeddings with `n_neighbors=15`, `n_components=3`, and `cosine` distance metric. This projects the high-dimensional embeddings into a more compact representation while preserving local neighborhood structure. Clusters were then identified in this low-dimensional space using the HDBSCAN algorithm with `min_cluster_size=5`, `Euclidean` distance metric, and Excess of Mass method for cluster selection.

To further optimize the topic model, KeyBERT-inspired techniques were used to improve stop word removal, ensuring the most salient words characterize each topic. The final BERTopic model was fit using `min_topic_size=50` to remove small, noisy topics and the top 3 most representative words were extracted for each topic.

The resulting model identified more than 500 distinct, semantically meaningful topics across Jane Austen's literary works. A detailed view of the results showed above: 

![Topic performance](imgs/jane_books.png)

To further refine the topic model and uncover even more nuanced and meaningful topics, additional experimentation with hyperparameter tuning, custom pre-processing steps, and domain-specific keyword extraction techniques is warranted.


## Book Summary
Due to computational resource constraints, the book summarization experiment focused on analyzing a subset of chapters from the BookSum dataset, specifically several chapters from the classic novel "The Last of the Mohicans" by James Fenimore Cooper.

The abstractive summarization experiment explored LLama 3.1 with a reduced context window size, so I could assess the quality and capabilities of the tree summarization algorithm. This modification was necessary as the full model's context width of 128k tokens would have rendered the experiments inconclusive. The analysis was conducted on a limited sample of 10 randomly selected chapters from "The Last of the Mohicans" to accommodate resource constraints.

To enhance the summarization process, the model incorporated Retrieval-Augmented Generation (RAG) techniques, which provided additional context from relevant summarization and literacy articles. These articles offered guidance on crafting effective summaries. The experiment compared the performance of two approaches: the proposed method utilizing RAG and literacy know-how, and the LLM without these enhancements but with a limited context window and tree summarization algorithm enabled henceforth called `baseline`.

I used BLEU, ROUGE and METEOR as quantitative metrics to assess the quality of the model-generated summaries. The model achieved a ROUGE-1 F1 score of 0.36 (versus 0.40 of the baseline), ROUGE-2 F1 score of 0.07 (vs 0.08), and ROUGE-L F1 score of 0.2 (vs 0.2), indicating a reasonable degree of similarity between the model outputs and human-written summaries. The METEOR scores followed a similar trend to the ROUGE scores.

Although the quantitative metrics indicate comparable performance between the RAG + literacy approach and the simple LLM baseline, qualitative analysis reveals that the summaries generated by the RAG + literacy method provide more comprehensive and detailed information about the specific chapters. The incorporation of relevant summarization and literacy knowledge allows for a deeper understanding of the source material, resulting in summaries that capture the nuances and key aspects of each chapter more effectively.



***
***

Follows the generated summaries for Chapter 24 of the "The Last of the Mohicans".

**Baseline:**
***Heyward is in a Huron village, searching for Alice. He encounters Uncas, who is being held captive, and Magua, a cunning and feared Huron warrior. Magua delivers a powerful speech, stirring up the Hurons' desire for revenge against the Delawares, and they decide to make Uncas carry a heavy burden as punishment. Heyward is relieved when Magua leaves, but the Hurons' intentions remain ominous.***

***Heyward is then led by a Huron chief to a cavern in the mountains, where a sick woman is being held. He is surprised to find David, a friend, there, and  discovers that the woman is beyond his powers to heal. David attempts to use  music to help the woman, but is interrupted by a strange echo from a bear that  has followed them into the cavern. The bear's presence causes a commotion, and  David leaves, saying that someone is expected and is at hand.***

***

**RAG+Literacy:**
***Heyward is in a Huron village, trying to find information about Alice, who has been taken captive. He encounters Uncas, who is being held captive by the Hurons. Magua, a Huron chief, returns to the village and begins to speak about the death of his young men and the need for revenge against the Delawares. He singles out Uncas, calling him "Le Cerf Agile" and threatening to kill him. The Hurons tie Uncas up and prepare to take him away, but not before he gives Heyward a hopeful glance.***

***Heyward is then taken to see a sick woman who is believed to be possessed by an evil spirit. He meets David, who is also in the village, and they both try to  help the woman. However, their attempts are interrupted by a bear that enters the cave and causes a commotion. The bear is eventually calmed down, and Heyward and David are able to continue their attempts to help the woman.*** 

***Meanwhile, Magua is planning his revenge against the Delawares and is determined  to kill Uncas. The Hurons are preparing for battle, and Heyward and David are  trying to find a way to escape and warn the Delawares about the impending attack.***

***
***

The similarity between the results obtained from the RAG + literacy approach and the simple LLM baseline may be attributed to several factors:

1. The robust linguistic performance of the baseline LLM, which has already demonstrated strong capabilities across various dimensions on the LLMs leaderboard, may have limited the potential for significant improvements.
2. The sentence transformer used for indexing the book chapters, specifically the `all-MiniLm-L6` model, may have provided only fair performance in capturing the semantic meaning and relevance of the text, potentially limiting the effectiveness of the retrieval process.
3. The use of a simple VectorStoreIndex without the support of a dedicated vector store engine like Pinecone or Qdrant may have restricted the quality, efficiency and scalability of the retrieval process, impacting the overall performance.
4. The selection of literacy articles used to guide the summarization process may not have been optimal, and better-curated articles could potentially lead to improved summary quality.
5. The lack of extensive parameter tuning and optimization may have hindered the ability to fully leverage the capabilities of the RAG + literacy approach, leaving room for further improvement with more comprehensive experimentation and fine-tuning.

These factors highlight the complexities involved in enhancing summarization performance and the need for careful consideration of various components, including the underlying LLM, indexing techniques, retrieval mechanisms, and domain-specific knowledge integration. Further research and experimentation are necessary to identify the most effective combination of techniques and resources for generating high-quality summaries.



